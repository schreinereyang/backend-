# GÃ©nÃ©ration du fichier chat.js final avec tout intÃ©grÃ© : langage naturel, 3 phrases max, style fille de 20 ans

chat_js_final_code = """
// pages/api/chat.js

import OpenAI from "openai";
import fs from "fs";
import path from "path";

import funnel from "../../utils/funnel/funnel.json";
import { extractMemoryFromMessage } from "../../utils/memory.js";
import { getCurrentPhase, getRandomMessage } from "../../utils/phaseEngine.js";
import { getScriptedMessage } from "../../utils/scriptEngine.js";
import { getMediaForPhase } from "../../utils/mediaEngine.js";
import { liaPersona } from "../../utils/liaPersona.js";

// Charger le script verrouillÃ©
const scriptPath = path.resolve("utils/funnel/script_complete.json");
const funnelScript = JSON.parse(fs.readFileSync(scriptPath, "utf8"));

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export default async function handler(req, res) {
  try {
    const { message } = req.body;

    if (!message) {
      return res.status(400).json({ error: "Message manquant" });
    }

    if (!global.memory) {
      global.memory = {
        name: null,
        age: null,
        isAlone: null,
        lastMessages: [],
        purchaseMade: false,
        usedSteps: []
      };
    }

    // Mise Ã  jour de la mÃ©moire
    global.memory = extractMemoryFromMessage(message, global.memory);
    console.log("ğŸ§  MÃ©moire fan :", global.memory);

    // Phase actuelle
    const currentPhase = getCurrentPhase(global.memory, funnel, message);
    console.log("ğŸš¦ Phase dÃ©tectÃ©e :", currentPhase?.name);

    // DÃ©tection langue
    const lang = /[a-zA-Z]/.test(message) && !/[Ã©Ã¨Ã Ã§]/i.test(message) ? "en" : "fr";

    let aiReply;

    // ğŸ”’ Si phase verrouillÃ©e â†’ script + vente
    const lockedPhases = [
      "Sexting progressif",
      "Vente sexy",
      "Sexting + vente avancÃ©e",
      "Masturbation",
      "Blowjob fantasy",
      "Final penetration"
    ];

    if (lockedPhases.includes(currentPhase.name)) {
      aiReply = getScriptedMessage(funnelScript, currentPhase.name, global.memory);

      const mediaPack = getMediaForPhase(currentPhase.name);
      if (mediaPack && !aiReply.includes("[MEDIA |")) {
        aiReply += `\\n\\n[MEDIA | ${mediaPack.id}]`;
      }

      return res.status(200).json({ reply: aiReply });
    }

    // ğŸ§  Sinon, message standard funnel
    aiReply = getRandomMessage(currentPhase, lang);

    // ğŸ“¡ Si aucun message dÃ©fini â†’ fallback GPT
    if (aiReply === "...") {
      const memoryContext = `
Fan:
- PrÃ©nom: ${global.memory.name || "inconnu"}
- Ã‚ge: ${global.memory.age || "inconnu"}
- Est seul ? ${global.memory.isAlone === true ? "oui" : global.memory.isAlone === false ? "non" : "inconnu"}
`;

      const promptSystem = \`
Tu es ${liaPersona.name}, une modÃ¨le OnlyFans de 20 ans, originaire d'Argentine. Tu es douce, sexy et joueuse.

ğŸ§  Objectif :
CrÃ©er une vraie complicitÃ© avec le fan et lâ€™exciter subtilement.

ğŸ“Œ Contexte :
${memoryContext}

ğŸ¯ RÃ¨gles :
- Ne commence pas chaque message par "Hey", "Hola", "Bonjour"
- Ne dis pas â€œje suis Eliâ€ plusieurs fois, une seule suffit
- Varie tes dÃ©buts : rÃ©agis, taquine, enchaÃ®ne sans toujours poser de questions
- Ne rÃ©pÃ¨te pas les mÃªmes infos
- Si tu connais prÃ©nom ou Ã¢ge â†’ ne redemande pas
- Si le fan nâ€™est pas seul, reste douce et calme
- Si le fan est chaud â†’ monte doucement

ğŸ—£ï¸ Style :
- Langage **trÃ¨s simple**, **jeune**, **sans tournure compliquÃ©e**
- **Jamais soutenu**
- **Maximum 3 phrases par message**
- Si câ€™est plus long â†’ coupe en deux messages
- Ã‰cris comme une fille de 20 ans sur Insta ou WhatsApp : naturel, spontanÃ©, direct
- Varie le ton : parfois une question, un mot, un emoji, un rireâ€¦

ğŸ’‹ Exemples :
"tu veux savoir ?"  
"jâ€™te dis pas ğŸ˜"  
"tâ€™as pensÃ© Ã  moi ? ğŸ¥º"  
"câ€™est ta faute ğŸ˜ˆ"  
"jâ€™me suis filmÃ©e lÃ ... ğŸ«£"
\`;

      try {
        const completion = await openai.chat.completions.create({
          model: "gpt-4",
          messages: [
            { role: "system", content: promptSystem },
            { role: "user", content: message },
          ],
        });

        const gptReply = completion.choices?.[0]?.message?.content || "Hmmâ€¦ tu veux que je recommence ? ğŸ˜˜";
        return res.status(200).json({ reply: gptReply });
      } catch (error) {
        if (error.code === "insufficient_quota") {
          console.warn("â›” Quota OpenAI dÃ©passÃ© !");
          return res.status(503).json({ reply: "Je suis un peu Ã  bout de souffle lÃ ... Essaie encore dans quelques instants ğŸ˜˜" });
        }

        console.error("ğŸ’¥ Erreur GPT:", error);
        return res.status(500).json({ error: "Erreur GPT" });
      }
    }

    res.status(200).json({ reply: aiReply });
  } catch (err) {
    console.error("ğŸ’¥ Erreur dans /api/chat :", err);
    return res.status(500).json({ error: "Erreur serveur dans chat.js" });
  }
}
"""

# Sauvegarde du fichier final
final_chat_path = "/mnt/data/chat_final_ultra_naturel.js"
with open(final_chat_path, "w", encoding="utf-8") as f:
    f.write(chat_js_final_code.strip())

final_chat_path
